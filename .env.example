# --- OpenAI (optional) ---
# OPENAI_API_KEY=sk-yourkeyhere

# --- Ollama ---
# Uncomment ONE of these depending on how you run

Running with Streamlit directly:
OLLAMA_URL=http://localhost:11434

# Running inside Docker:
#OLLAMA_URL=http://host.docker.internal:11434

#OLLAMA_MODEL=llama3.1:8b-instruct-q8_0
